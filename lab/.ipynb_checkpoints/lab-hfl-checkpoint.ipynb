{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the lab on Horizontal Federated Learning, comprised of Tutorials 1A, 1B, and Homework 1, presents the findings and uses part of the experimental methodology from the [original Federated Learning](https://arxiv.org/pdf/1602.05629.pdf) paper. In horizontal federated learning, all clients have access to the same complete model architecture, which they train on local data, sharing information about model updates but not their data.\n",
    "\n",
    "Before starting, make sure to follow the overall setup for the lab.\n",
    "\n",
    "This first tutorial sets up some of the prerequisite code for later on and reproduces a basic centralized training setup where the server has all the data and involves no other clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, we download, load, and preprocess the [MNIST dataset](https://archive.ics.uci.edu/dataset/683/mnist+database+of+handwritten+digits), which we will use for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_path_str = \"./data\"\n",
    "ETA = \"\\N{GREEK SMALL LETTER ETA}\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # normalize by training set mean and standard deviation\n",
    "    # resulting data has mean=0 and std=1\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_path_str, train=True, download=True, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path_str, train=False, download=False, transform=transform),\n",
    "    # decrease batch size if running into memory issues when testing\n",
    "    # a bespoke generator is passed to avoid reproducibility issues\n",
    "    shuffle=False, drop_last=False, batch_size=10000, generator=torch.Generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a small convolutional neural network that will serve as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MnistCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can define a helper method, which, given a model, a loader for iterating through a set of data, and an optimizer for updating the model trains one epoch (i.e., learns going through all the available data once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, loader: DataLoader, optimizer: Optimizer) -> None:\n",
    "    model.train()\n",
    "\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define another utility method that splits the whole dataset into the requested number of chunks, picking samples within chunks in a (non-)IID (independent and identically distributed) fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def split(nr_clients: int, iid: bool, seed: int) -> list[Subset]:\n",
    "    rng = npr.default_rng(seed)\n",
    "\n",
    "    if iid:\n",
    "        splits = np.array_split(rng.permutation(len(train_dataset)), nr_clients)\n",
    "    else:\n",
    "        sorted_indices = np.argsort(np.array([target for _data, target in train_dataset]))\n",
    "        shards = np.array_split(sorted_indices, 2 * nr_clients)\n",
    "        shuffled_shard_indices = rng.permutation(len(shards))\n",
    "        splits = [\n",
    "            np.concatenate([shards[i] for i in inds], dtype=np.int64)\n",
    "            for inds in shuffled_shard_indices.reshape(-1, 2)]\n",
    "\n",
    "    return [Subset(train_dataset, split) for split in cast(list[list[int]], splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_split = split(100, True, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a short class for holding the results of training runs and the parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass, field\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    algorithm: str\n",
    "    n: int  # number of clients\n",
    "    c: float  # client_fraction\n",
    "    b: int  # take -1 as inf\n",
    "    e: int  # nr_local_epochs\n",
    "    lr: float  # printed as lowercase eta\n",
    "    seed: int\n",
    "    wall_time: list[float] = field(default_factory=list)\n",
    "    message_count: list[int] = field(default_factory=list)\n",
    "    test_accuracy: list[float] = field(default_factory=list)\n",
    "\n",
    "    def as_df(self, skip_wtime=True) -> DataFrame:\n",
    "        self_dict = {\n",
    "            k.capitalize().replace(\"_\", \" \"): v\n",
    "            for k, v in asdict(self).items()}\n",
    "\n",
    "        if self_dict[\"B\"] == -1:\n",
    "            self_dict[\"B\"] = \"\\N{INFINITY}\"\n",
    "\n",
    "        df = DataFrame({\"Round\": range(1, len(self.wall_time) + 1), **self_dict})\n",
    "        df = df.rename(columns={\"Lr\": ETA})\n",
    "        if skip_wtime:\n",
    "            df = df.drop(columns=[\"Wall time\"])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an abstract class as a template for all distributed learning clients, defining a method for outputting an update after training a given model on local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Client(ABC):\n",
    "    def __init__(self, client_data: Subset, batch_size: int) -> None:\n",
    "        self.model = MnistCnn().to(device)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            client_data, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the flip side, a server needs to be able to run the (distributed) training process for a given number of rounds and test the current model it possesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(ABC):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        self.clients: list[Client]\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = MnistCnn().to(device)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        ...\n",
    "\n",
    "\n",
    "    def test(self) -> float:\n",
    "        correct = 0\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = self.model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        return 100. * correct / len(cast(datasets.MNIST, test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the previously defined server template, we can even formulate a centralized variant, which does not involve clients, as a precursor to distributed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "        self.clients = []\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\"Centralized\", 1, 1, self.batch_size, 1, self.lr, self.seed)\n",
    "\n",
    "        for epoch in tqdm(range(nr_rounds), desc=\"Epochs\", leave=False):\n",
    "            start_time = perf_counter()\n",
    "            self.generator.manual_seed(self.seed + epoch + 1)\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "            elapsed_time += perf_counter() - start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(0)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncentralized_server = CentralizedServer(0.5, 128, 42)\\nresult_centralized = centralized_server.run(3)\\ncentralized_df = result_centralized.as_df()\\ncentralized_df\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "centralized_server = CentralizedServer(0.5, 128, 42)\n",
    "result_centralized = centralized_server.run(3)\n",
    "centralized_df = result_centralized.as_df()\n",
    "centralized_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the template with some setup steps common to all decentralized algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.nr_clients = len(client_subsets)\n",
    "        self.client_fraction = client_fraction\n",
    "        self.client_sample_counts = [len(subset) for subset in client_subsets]\n",
    "        self.nr_clients_per_round = max(1, round(client_fraction * self.nr_clients))\n",
    "        self.rng = npr.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second tutorial implements the two federated learning algorithms from the same paper referenced previously and gives a quick overview of plotting metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the FedSGD algorithm, the baseline from the paper, we first need to define the client, and we choose to pass gradients from the client as the update result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientClient(Client):\n",
    "    def __init__(self, client_data: Subset) -> None:\n",
    "        super().__init__(client_data, len(client_data))\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # do the local training and send back the gradients\n",
    "\n",
    "        # copy the data from the server\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "                client_values.grad = None\n",
    "\n",
    "        # seeding is not strictly necessary here\n",
    "        self.generator.manual_seed(seed)\n",
    "        self.model.train()\n",
    "\n",
    "        # this will always have one iteration on the batch with all entries\n",
    "        for data, target in self.loader_train:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "        # send back the gradient to the server\n",
    "        return [\n",
    "            cast(torch.Tensor, x.grad).detach().cpu().clone()\n",
    "            for x in self.model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the corresponding server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decentralized cause everyone has its own data\n",
    "\n",
    "class FedSgdGradientServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float,\n",
    "            client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, -1, client_subsets, client_fraction, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.clients = [GradientClient(subset) for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0. # starting a timer\n",
    "        run_result = RunResult(\"FedSGDGradient\", self.nr_clients, self.client_fraction, -1, 1, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train() # training mode\n",
    "            self.optimizer.zero_grad() # ensure clean gradients\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()] # will be sent to the clients\n",
    "            indices_chosen_clients = self.rng.choice(self.nr_clients, self.nr_clients_per_round, replace=False) # nb of clients that will be communicate with fot a round\n",
    "            chosen_sum_nr_samples = sum(self.client_sample_counts[i] for i in indices_chosen_clients)\n",
    "            chosen_adjusted_gradients: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            # getting the updates from the clients\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_gradients = self.clients[ind].update(weights, client_round_seed) # compute your updates\n",
    "                chosen_adjusted_gradients.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_gradients]) # weighted averaging comparing how many sample the client has compared to the total\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_gradients: list[torch.Tensor] = [sum(x) for x in zip(*chosen_adjusted_gradients)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for client_gradient, server_parameter in zip(averaged_chosen_gradients, self.model.parameters()):\n",
    "                    server_parameter.grad = client_gradient.to(device=device) # from the clients update to the server meaning after that our model has been updated\n",
    "\n",
    "            self.optimizer.step()\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>9.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>11.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>16.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round       Algorithm   N    C  B  E     η  Seed  Message count  \\\n",
       "0      1  FedSGDGradient  10  0.2  ∞  1  0.02    42              4   \n",
       "1      2  FedSGDGradient  10  0.2  ∞  1  0.02    42              8   \n",
       "2      3  FedSGDGradient  10  0.2  ∞  1  0.02    42             12   \n",
       "3      4  FedSGDGradient  10  0.2  ∞  1  0.02    42             16   \n",
       "4      5  FedSGDGradient  10  0.2  ∞  1  0.02    42             20   \n",
       "\n",
       "   Test accuracy  \n",
       "0           9.47  \n",
       "1           9.67  \n",
       "2           9.99  \n",
       "3          11.81  \n",
       "4          16.10  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedsgd_gradient_server = FedSgdGradientServer(0.02, sample_split, 0.2, 42)\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FedAvg algorithm is the paper's main contribution, requiring a client that passes around weights instead of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightClient(Client):\n",
    "    def __init__(self, client_data: Subset, lr: float, batch_size: int, nr_epochs: int) -> None:\n",
    "        super().__init__(client_data, batch_size)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.nr_epochs = nr_epochs\n",
    "\n",
    "    # get the weights from the server\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "\n",
    "        self.generator.manual_seed(seed) # for reproducibility reasons\n",
    "\n",
    "        for _epoch in range(self.nr_epochs):\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "\n",
    "        return [x.detach().cpu().clone() for x in self.model.parameters()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we define the actual server code for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, nr_local_epochs: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedAvg\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(self.name, self.nr_clients, self.client_fraction, self.batch_size, self.nr_local_epochs, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(self.nr_clients, self.nr_clients_per_round, replace=False)\n",
    "            chosen_sum_nr_samples = sum(self.client_sample_counts[i] for i in indices_chosen_clients)\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_weights])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_weights: list[torch.Tensor] = [sum(x) for x in zip(*chosen_adjusted_weights)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for client_weight, server_parameter in zip(averaged_chosen_weights, self.model.parameters()):\n",
    "                    server_parameter[:] = client_weight.to(device=device)\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>81.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>89.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>91.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>92.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>92.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round Algorithm   N    C    B  E     η  Seed  Message count  Test accuracy\n",
       "0      1    FedAvg  10  0.2  200  2  0.02    42              4          81.88\n",
       "1      2    FedAvg  10  0.2  200  2  0.02    42              8          89.34\n",
       "2      3    FedAvg  10  0.2  200  2  0.02    42             12          91.15\n",
       "3      4    FedAvg  10  0.2  200  2  0.02    42             16          92.43\n",
       "4      5    FedAvg  10  0.2  200  2  0.02    42             20          92.91"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedavg_server = FedAvgServer(0.02, 200, sample_split, 0.2, 2, 42)\n",
    "result_fedavg = fedavg_server.run(5)\n",
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at a quick example of plotting the accuracy per round of the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABB4UlEQVR4nO3dd3wUdf7H8fduekISCCGNllCkSJfeLKCIykkRBRERUe78IYooKqAIiqCIgliix0XAU8AKnHiiiAcIIuRAOCnSREFJQBA2CSFtd35/JFmyKZANSTYDr+fjsY/stO98NhuZt9/5zozFMAxDAAAAJmT1dAEAAABlRZABAACmRZABAACmRZABAACmRZABAACmRZABAACmRZABAACm5e3pAiqaw+HQ0aNHFRwcLIvF4ulyAABAKRiGodTUVMXExMhqLbnf5ZIPMkePHlXdunU9XQYAACiDI0eOqE6dOiUuv+SDTHBwsKTcX0RISIiHqwEAAKWRkpKiunXrOo/jJbnkg0z+6aSQkBCCDAAAJnOhYSEM9gUAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZFkAEAAKZ1yT80EgAAXBzDMJRtN2R3GMpxOJRjN5TjyJ3OtjtUPdBHwf4+HqmNIAMAQBkVd2DPsTtcDvK5PwuEAIeRt37eegXfO9d1FNjmXJs5ectynPNd28l2OFy2KbLvvDrz3zvXdTjytnetO78dh3H+38MLA1tqSMd6lfNLL4QgAwCoNA6HobPZdp3JylF6pl3pWXZlFzjwOw/YBQ60uQfXogf24g7yOUXWLdrOuYO5a+hwbadwCCh4sD+3b+MCB/hLnY+XRV5WiywWz9VAkAEAFGEYeYEj066zWXnBIytH6Vm589KzcnQmy66zWTnO6fQse97ynLxt89bPysltI9Ous9l2T3+0Cme1SN5Wq7zzDvI+XlZ5WS3ytlrk7WXJXWbNXVZ4On/d/IDg0o7VKi+vvHby5nvntetVYLpoO9YC+87dtnA7zvaL2XfutkU/g5fVg+mlAIIMAJiYYRjKzHE4Q0N+cEjPLBAgCvR+5AaQvHUz7efe5y/LzA0n6dn2Cu1tsFikIF9vBfh6yTf/IHmeg+u5g7S1wIE29wBb+ODqsq7VIi+vwu2c26a4A/a5MFBCCCimHed8q0XWKnKAv1wQZACgEuQHjnO9G3k9F1l2ncmyF+jtKNqLca63I8fZq3EuuORccPzCxQr09VKgr3feTy8F+RV47+utQL9zy89N587LDytBfnnL8ub7+1hl8eT5CFwyCDIAUEhWjqPIqZNzvRt2pWcWWJY37dIbkh9MCvV42Cs4cfj7WJ1BwhkgCgSQQD9vBRUMJc7pvNDhVzCw5E77e3vRw4AqjSADwLRy7A5nb0bhsRyu0+fWORdQXHs1Co7tyLZXbODw87aeNzyc683IDRsFpwMK9IgEFQgkAT5eVWbMAlCZCDIAPCZ/QGnK2RzZzmbLdjZbKfk/M/KncwpNn1vnTFbFDhz19bIW6t0o2psRUOB0iksviJ+XAn0KhA6/3GWBPl7y9uJepEB5IcgAuCh2h5EbLs4TPJwhJSN3WWqBsFIevR/eVkuhsRuu4SGomN6PgmM3Co/lyF/Hh8ABVHkEGeAyZxiGMrIdRYJHSka2bOnZsp3NKWZZjrNnJDUz56Jr8LJaFOLvrdAAH4UG+Cgk/+WfP5277Nx03k9/bwX7+8jXm8ABXK4IMsAlwO4wlJZR4PRMcaGkxNM0OcqyOy66hkBfr2KDR0iB4JEfPlzCSICPgny9uIIFQJkQZIAqIiPbXnLwcDk9UzSUpGZcfK+I1aICPR0FgkeAd6HeEddAEhrgQ68IAI8hyADlxOEwlJqZcy6MlKI3pOC4kayci+8VCfDxOu9pmKK9Iz4KDcxdVs3Pm14RAKZDkAEKyMyxFwgZOYUGsboGksKhJDUz56LvhGqxqMRxIa5jRwqdnvHPXd/P26t8fhEAYBIEGVx2/jyTpe8OntDGAye071iaS0jJLIdeET9vq0vwKHZciHPsiOsA12q+3tx8DADcQJDBJS8j267EX/7UhgO54WXX0ZTz9pxYLFKwn3feKRefQqdpzn9lTYi/j/x96BUBgMpCkMElx+4wtOuozRlcEn85VWT8SdOoYHVrFK629aorLNDX5QqaYD96RQDALAgyMD3DMHT4z3RtOHBCG/af0HcHT8p2NttlnagQf3VvHK7ujcLVtVFNRQT7e6haAEB5IsjAlPLHuWzYf0IbDpzQb6fOuiwP9vNW54Y11aNxuLo1CleD8CCuyAGASxBBBqaQkW3XlkN/auOB3OCy62iKy3IfL4va1quhHo3C1a1xuFrVDuV5NgBwGSDIoEqyOwzt/P3cOJf//lr8OJfuecGlY2yYgvz4cwaAyw3/8qNKMAxDv55MdwaX4sa5RIf6q3ujcHVvHK4uDRnnAgAgyMCDTqZl6ruDJ7XxwAl9u/+Efj9ddJxLl4Y11Z1xLgCAEhBkUGnOZp27n8uG/Se0O6noOJd29Wo4TxcxzgUAcCEEGVSYguNcNuw/oa2/nirylOX8cS7dG4erY1yYAn35kwQAlB5HDZQbwzD0S/44l/0n9N3BE0op9FTmmFB/dcsLLl0bhqtWsJ+HqgUAXAoIMrgoJ/LHueTdz6XIOBd/b3VtWDP3dFGjcMUxzgUAUI4IMnDL2Sy7tvzyp3OA7p5ixrlcVb+GM7i0ZJwLAKACEWRwXnaHoR9/t+UFlz+07dfTRca5NIsOUfdGNdWtEeNcAACViyMOXBQc57Jh/x/adPBkseNc8i+J7tYoXOHVGOcCAPAMggx0Ii1TG/NuRLfxwMnzjnPp3riWYmsGMs4FAFAlEGQuQ+lZOQWeW3SyyDgXXy+r2tWvrh6Na6lbo3C1iAlhnAsAoEoiyFwG7A5D//vttPOBi8WNc2keHeI8XdQhtgbjXAAApsDR6hJkGIYOnTjjDC7fHTyp1ELjXGpXD3DeQbdrw5qMcwEAmBJB5hLxR2qmvjuYewfdjQdO6Kgtw2V5iL+3ujbMDS7dG4UzzgUAcEkgyJhU/jiXDXk3ovspOdVlua+XNfd+LnnBpUXtUHlZCS4AgEsLQcYkcuwO/fi7zRlcth0+pWy74bJO/jiX7o3C1SE2TAG+Xh6qFgCAykGQqaIMw9DP+eNc9p/Qpp+LH+fSI2+AbteGNVWTcS4AgMsMQaYKudA4l9AAH3VtmHsH3e6NwlWfcS4AgMscQcaD0rNytPnQn84HLhY3zqV9bA1ncGGcCwAArggylSjH7tD/frdp4/4T+vbACf1QzDiXK2NCnA9cZJwLAADnR5CpQPnjXPIH6H5/8KRSM4sf59K9cbi6NGCcCwAA7iDIlLM/UjOdN6LbeOCEkkoY55J/dVG9MMa5AABQVgSZi3QmM+9+LnnBpcg4F2+rOhQY53JlDONcAAAoLwSZMnp/869asf1okXEuFkvuOJf84NK+PuNcAACoKASZMtp9NEVbDv0pSapTo+D9XMIVFuTr4eoAALg8EGTKaNBVddQ87wqj+jWDPF0OAACXJYJMGbWrV0Pt6tXwdBkAAFzWrJ4uAAAAoKw8GmTsdruefvppxcXFKSAgQA0bNtRzzz0nwzg3eNYwDE2ZMkXR0dEKCAhQ7969tX//fg9WDQAAqgqPBpkXX3xR8fHxev3117Vnzx69+OKLmjVrll577TXnOrNmzdK8efP01ltvafPmzQoKClKfPn2UkZFxnpYBAMDlwGIU7P6oZLfccosiIyOVkJDgnDdo0CAFBATovffek2EYiomJ0aOPPqrHHntMkmSz2RQZGamFCxdqyJAhF9xHSkqKQkNDZbPZFBISUmGfBQAAlJ/SHr892iPTtWtXrVmzRvv27ZMk7dixQxs2bFDfvn0lSYcOHVJycrJ69+7t3CY0NFSdOnXSpk2bim0zMzNTKSkpLi8AAHBp8uhVS08++aRSUlLUtGlTeXl5yW636/nnn9ewYcMkScnJyZKkyMhIl+0iIyOdywqbOXOmpk2bVrGFAwCAKsGjPTIffvih3n//fS1evFjbtm3TokWLNHv2bC1atKjMbU6cOFE2m835OnLkSDlWDAAAqhKP9shMmDBBTz75pHOsS8uWLfXrr79q5syZGjFihKKioiRJx44dU3R0tHO7Y8eOqU2bNsW26efnJz8/niANAMDlwKM9Munp6bJaXUvw8vKSw+GQJMXFxSkqKkpr1qxxLk9JSdHmzZvVpUuXSq0VAABUPR7tkenXr5+ef/551atXT1deeaV++OEHvfLKK7r33nslSRaLRePGjdP06dPVuHFjxcXF6emnn1ZMTIz69+/vydIBAEAV4NEg89prr+npp5/W//3f/+n48eOKiYnRX//6V02ZMsW5zuOPP64zZ85o9OjROn36tLp3765Vq1bJ39/fg5UDAICqwKP3kakM3EcGAADzMcV9ZAAAAC4GQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJgWQQYAAJiW20EmNjZWzz77rA4fPlwR9QAAAJSa20Fm3Lhx+vTTT9WgQQNdf/31Wrp0qTIzMyuiNgAAgPMqU5DZvn27tmzZombNmmns2LGKjo7Wgw8+qG3btlVEjQAAAMWyGIZhXEwD2dnZevPNN/XEE08oOztbLVu21EMPPaSRI0fKYrGUV51llpKSotDQUNlsNoWEhHi6HAAAUAqlPX57l3UH2dnZWrZsmRYsWKDVq1erc+fOGjVqlH777TdNmjRJX3/9tRYvXlzW5gEAAC7I7SCzbds2LViwQEuWLJHVatXdd9+tOXPmqGnTps51BgwYoA4dOpRroQAAAIW5PUamQ4cO2r9/v+Lj4/X7779r9uzZLiFGkuLi4jRkyJBStff777/rrrvuUs2aNRUQEKCWLVvqv//9r3O5YRiaMmWKoqOjFRAQoN69e2v//v3ulg0AAC5BbvfI/Pzzz6pfv/551wkKCtKCBQsu2NapU6fUrVs3XXvttfriiy9Uq1Yt7d+/XzVq1HCuM2vWLM2bN0+LFi1SXFycnn76afXp00e7d++Wv7+/u+UDAIBLiNuDfRMTE+VwONSpUyeX+Zs3b5aXl5fat29f6raefPJJbdy4Ud9++22xyw3DUExMjB599FE99thjkiSbzabIyEgtXLiw2F6fzMxMl8vBU1JSVLduXQb7AgBgIqUd7Ov2qaUxY8boyJEjReb//vvvGjNmjFtt/etf/1L79u01ePBgRUREqG3btpo/f75z+aFDh5ScnKzevXs754WGhqpTp07atGlTsW3OnDlToaGhzlfdunXdqgkAAJiH26eWdu/erXbt2hWZ37ZtW+3evduttn7++WfFx8dr/PjxmjRpkhITE/XQQw/J19dXI0aMUHJysiQpMjLSZbvIyEjnssImTpyo8ePHO6fze2QAALnsdruys7M9XQYucz4+PvLy8rrodtwOMn5+fjp27JgaNGjgMj8pKUne3u4153A41L59e82YMUNSbhjauXOn3nrrLY0YMcLd0pz1+fn5lWlbALiUGYah5ORknT592tOlAJKk6tWrKyoq6qLuO+d2kLnhhhs0ceJErVixQqGhoZKk06dPa9KkSbr++uvdais6OlrNmzd3mdesWTN98sknkqSoqChJ0rFjxxQdHe1c59ixY2rTpo27pQPAZS0/xERERCgwMLBK3LQUlyfDMJSenq7jx49Lkssx3l1uB5nZs2erZ8+eql+/vtq2bStJ2r59uyIjI/XPf/7Trba6deumvXv3uszbt2+f86qouLg4RUVFac2aNc7gkpKSos2bN+uBBx5wt3QAuGzZ7XZniKlZs6anywEUEBAgSTp+/LgiIiLKfJrJ7SBTu3Zt/e9//9P777+vHTt2KCAgQCNHjtTQoUPl4+PjVluPPPKIunbtqhkzZuj222/Xli1b9Pe//11///vfJUkWi0Xjxo3T9OnT1bhxY+fl1zExMerfv7+7pQPAZSt/TExgYKCHKwHOyf97zM7OrrwgI+XeJ2b06NFl2mFBHTp00LJlyzRx4kQ9++yziouL09y5czVs2DDnOo8//rjOnDmj0aNH6/Tp0+revbtWrVrFPWQAoAw4nYSqpDz+Hsv80Mjdu3fr8OHDysrKcpn/l7/85aKLKk88NBIApIyMDB06dEhxcXH8jyCqjPP9XVbYQyN//vlnDRgwQD/++KMsFovyc1B+qrLb7e42CQAAUCZu3xDv4YcfVlxcnI4fP67AwEDt2rVL69evV/v27bV27doKKBEAgNJbu3atLBZLpVxmXtp9xcbGau7cuRVez+XI7SCzadMmPfvsswoPD5fVapXValX37t01c+ZMPfTQQxVRIwAARWzatEleXl66+eabPVZD165dlZSU5LwdycKFC1W9enWP1XM5cjvI2O12BQcHS5LCw8N19OhRSVL9+vWLXEoNAEBFSUhI0NixY7V+/XrnsagyZWdny9fX96Jv6IaL43aQadGihXbs2CFJ6tSpk2bNmqWNGzfq2WefLXK3XwAAKkJaWpo++OADPfDAA7r55pu1cOHC864/f/581a1bV4GBgRowYIBeeeWVIj0n8fHxatiwoXx9fdWkSZMi90azWCyKj4/XX/7yFwUFBen55593ObW0du1ajRw5UjabTRaLRRaLRVOnTnVun56ernvvvVfBwcGqV6+e81YjkvTLL7/IYrHoww8/VI8ePRQQEKAOHTpo3759SkxMVPv27VWtWjX17dtXf/zxx8X++i4thptWrVplfPLJJ4ZhGMb+/fuNJk2aGBaLxQgPDzfWrFnjbnMVzmazGZIMm83m6VIAwGPOnj1r7N692zh79qynSykXCQkJRvv27Q3DMIzPPvvMaNiwoeFwOAzDMIz//Oc/hiTj1KlThmEYxoYNGwyr1Wq89NJLxt69e4033njDCAsLM0JDQ53tffrpp4aPj4/xxhtvGHv37jVefvllw8vLy/jmm2+c60gyIiIijHfeecc4ePCg8euvv7rsKzMz05g7d64REhJiJCUlGUlJSUZqaqphGIZRv359IywszHjjjTeM/fv3GzNnzjSsVqvx008/GYZhGIcOHTIkGU2bNjVWrVpl7N692+jcubNx1VVXGddcc42xYcMGY9u2bUajRo2Mv/3tb5XwG64c5/u7LO3x2+0gU5yTJ086/4CqGoIMAFx6QaZr167G3LlzDcMwjOzsbCM8PNz4z3/+YxhG0SBzxx13GDfffLPL9sOGDXMJMl27djXuv/9+l3UGDx5s3HTTTc5pSca4ceNc1im8rwULFri0m69+/frGXXfd5Zx2OBxGRESEER8fbxjGuSDzj3/8w7nOkiVLDEkunQQzZ840mjRpcp7fjLmUR5Bx69RSdna2vL29tXPnTpf5YWFhnB8EAFSKvXv3asuWLRo6dKgkydvbW3fccYcSEhJKXL9jx44u8wpP79mzR926dXOZ161bN+3Zs8dlXvv27ctcd6tWrZzvLRaLoqKinM8aKm6dyMhISVLLli1d5hXe5nLn1n1kfHx8VK9ePe4VAwDwmISEBOXk5CgmJsY5zzAM+fn56fXXX6/QfQcFBZV528KP8bFYLHI4HCWuk99BUHhe4W0ud24P9p08ebImTZqkP//8syLqAQCgRDk5OXr33Xf18ssva/v27c7Xjh07FBMToyVLlhTZpkmTJkpMTHSZV3i6WbNm2rhxo8u8jRs3qnnz5m7V5+vry//sVzK37+z7+uuv68CBA4qJiVH9+vWLpNNt27aVW3EAABS0cuVKnTp1SqNGjXLeuyXfoEGDlJCQoJdeesll/tixY9WzZ0+98sor6tevn7755ht98cUXLkMiJkyYoNtvv11t27ZV79699dlnn+nTTz/V119/7VZ9sbGxSktL05o1a9S6dWsFBgbyoM4K5naQ4anTAABPSUhIUO/evYuEGCk3yMyaNUv/+9//XOZ369ZNb731lqZNm6annnpKffr00SOPPOJyGqp///569dVXNXv2bOcd7BcsWKBrrrnGrfq6du2qv/3tb7rjjjt08uRJPfPMMy6XYKP8lfmhkWbBQyMBgIdGFnb//ffrp59+0rfffuvpUi5rHnloJAAAZjN79mxdf/31CgoK0hdffKFFixbpzTff9HRZKAduBxmr1XreS60Z5AQAqGq2bNmiWbNmKTU1VQ0aNNC8efN03333eboslAO3g8yyZctcprOzs/XDDz9o0aJFmjZtWrkVBgBAefnwww89XQIqiNtB5tZbby0y77bbbtOVV16pDz74QKNGjSqXwgAAAC7E7fvIlKRz585as2ZNeTUHAABwQeUSZM6ePat58+apdu3a5dEcAABAqbh9aqlGjRoug30Nw1BqaqoCAwP13nvvlWtxAAAA5+N2kJkzZ45LkLFarapVq5Y6deqkGjVqlGtxAAAA5+N2kLnnnnsqoAwAAAD3uT1GZsGCBfroo4+KzP/oo4+0aNGicikKAICKYrFYtHz5ck+XgXLidpCZOXOmwsPDi8yPiIjQjBkzyqUoAADy3XPPPbJYLEVeBw4cKNf9/PWvf5WXl1ex/7OOqsvtIHP48GHFxcUVmV+/fn0dPny4XIoCAKCgG2+8UUlJSS6v4o5FZZWenq6lS5fq8ccf1zvvvFNu7aLiuR1kIiIiijxZVJJ27NihmjVrlktRAICKZxiG0rNyPPJy93nFfn5+ioqKcnl5eXlpxYoVateunfz9/dWgQQNNmzZNOTk5zu3279+vnj17yt/fX82bN9fq1auLbf+jjz5S8+bN9eSTT2r9+vU6cuSIpNwHFwYEBOiLL75wWX/ZsmUKDg5Wenq6JOm7775TmzZt5O/vr/bt22v58uWyWCzavn27W58T7nN7sO/QoUP10EMPKTg4WD179pQkrVu3Tg8//LCGDBlS7gUCACrG2Wy7mk/50iP73v1sHwX6Xtxzi7/99lvdfffdmjdvnnr06KGDBw9q9OjRkqRnnnlGDodDAwcOVGRkpDZv3iybzaZx48YV21ZCQoLuuusuhYaGqm/fvlq4cKGefvpphYSE6JZbbtHixYvVt29f5/rvv/+++vfvr8DAQKWkpKhfv3666aabtHjxYv36668l7gflz+2/oueee06//PKLevXqJW/v3M0dDofuvvtuxsgAACrEypUrVa1aNed03759derUKT355JMaMWKEJKlBgwZ67rnn9Pjjj+uZZ57R119/rZ9++klffvmlYmJiJEkzZsxwCSRSbq/N999/r08//VSSdNddd2n8+PF66qmnZLFYNGzYMA0fPlzp6enO4PL55587nz24ePFiWSwWzZ8/39nz8/vvv+v++++vjF/NZc/tIOPr66sPPvhA06dP1/bt2xUQEKCWLVuqfv36FVEfAKCCBPh4afezfTy2b3dce+21io+Pd04HBQWpVatW2rhxo55//nnnfLvdroyMDKWnp2vPnj2qW7euM8RIUpcuXYq0/c4776hPnz7OC1luuukmjRo1St9884169eqlm266ST4+PvrXv/6lIUOG6JNPPlFISIh69+4tSdq7d69atWolf39/Z5sdO3Z06/Oh7Mrcr9e4cWM1bty4PGsBAFQii8Vy0ad3KktQUJAaNWrkMi8tLU3Tpk3TwIEDi6xfMFScj91u16JFi5ScnOw8y5A//5133lGvXr3k6+ur2267TYsXL9aQIUO0ePFi3XHHHS7rw3Pc/hYGDRqkjh076oknnnCZP2vWLCUmJnLZGgCgUrRr10579+4tEnDyNWvWTEeOHFFSUpKio6MlSd9//73LOv/+97+VmpqqH374QV5e53qJdu7cqZEjR+r06dOqXr26hg0bpuuvv167du3SN998o+nTpzvXbdKkid577z1lZmbKz89PkpSYmFjeHxclcPuqpfXr1+umm24qMr9v375av359uRQFAMCFTJkyRe+++66mTZumXbt2ac+ePVq6dKmeeuopSVLv3r11xRVXaMSIEdqxY4e+/fZbTZ482aWNhIQE3XzzzWrdurVatGjhfN1+++2qXr263n//fUlSz549FRUVpWHDhikuLk6dOnVytnHnnXfK4XBo9OjR2rNnj7788kvNnj1bklwe6YOK4XaQSUtLk6+vb5H5Pj4+SklJKZeiAAC4kD59+mjlypX66quv1KFDB3Xu3Flz5sxxjtm0Wq1atmyZzp49q44dO+q+++5zGU9z7Ngxff755xo0aFCRtq1WqwYMGKCEhARJuYFk6NCh2rFjh4YNG+aybkhIiD777DNt375dbdq00eTJkzVlyhRJpT/FhbKzGG5ezN+xY0fdcsstzi8p39SpU/XZZ59p69at5VrgxUpJSVFoaKhsNptCQkI8XQ4AeERGRoYOHTqkuLg4Dq6V4P3339fIkSNls9kUEBDg6XKqrPP9XZb2+O32GJmnn35aAwcO1MGDB3XddddJktasWaMlS5YwPgYAcFl699131aBBA9WuXVs7duzQE088odtvv50QUwncDjL9+vXT8uXLNWPGDH388ccKCAhQq1at9PXXX+vqq6+uiBoBAKjSkpOTNWXKFCUnJys6OlqDBw92OY2FiuP2qSWz4dQSAHBqCVVTeZxacnuwLwAAQFXh9qklu92uOXPm6MMPP9Thw4eVlZXlsvzPP/8st+IAAADOx+0emWnTpumVV17RHXfcIZvNpvHjx2vgwIGyWq2aOnVqBZQIAABQPLeDzPvvv6/58+fr0Ucflbe3t4YOHap//OMfmjJlSpE7JgIAAFQkt4NMcnKyWrZsKUmqVq2abDabJOmWW27R559/Xr7VAQAAnIfbQaZOnTpKSkqSJDVs2FBfffWVpNznSuQ/YwIAAKAyuB1kBgwYoDVr1kiSxo4dq6efflqNGzfW3XffrXvvvbfcCwQAoDxZLBYtX77c02V4zDXXXKNx48Y5p2NjYzV37lyP1XOx3A4yL7zwgiZNmiRJuuOOO/Ttt9/qgQce0Mcff6wXXnih3AsEAFze7rnnHlksliKvAwcOlEv769at03XXXaewsDAFBgaqcePGGjFihMtVuYZhaP78+erSpYtCQkJUrVo1XXnllXr44Ydd6pg6daqzPm9vb4WHh6tnz56aO3euMjMzi+z7wIEDuvfee1WvXj35+fmpdu3a6tWrl95//33l5OSUy+e7kMTERI0ePbpc2ywclirSRd9HpnPnzho/frz69etXHvUAAFDEjTfeqKSkJJdXXFzcRbe7e/du3XjjjWrfvr3Wr1+vH3/8Ua+99pp8fX1lt9sl5YaYO++8Uw899JBuuukmffXVV9q9e7cSEhLk7++v6dOnu7R55ZVXKikpSYcPH9Z//vMfDR48WDNnzlTXrl2VmprqXG/Lli1q166d9uzZozfeeEM7d+7U2rVrdd999yk+Pl67du0qse7s7OyL/uz5atWqpcDAwHJrr9IZlzibzWZIMmw2m6dLAQCPOXv2rLF7927j7Nmz52Y6HIaRmeaZl8NR6tpHjBhh3HrrrcUuW758udG2bVvDz8/PiIuLM6ZOnWpkZ2c7l+/bt8/o0aOH4efnZzRr1sz46quvDEnGsmXLDMMwjDlz5hixsbHn3f+SJUsMScaKFSuKXe4o8FmeeeYZo3Xr1kXW2bNnj+Hr62tMnjzZuU2zZs2Mq666yrDb7edt99ChQ4YkY+nSpUbPnj0NPz8/Y8GCBcaJEyeMIUOGGDExMUZAQIDRokULY/HixS5tpKWlGcOHDzeCgoKMqKgoY/bs2cbVV19tPPzww8516tevb8yZM8c5ferUKWPUqFFGeHi4ERwcbFx77bXG9u3bi3zGd99916hfv74REhJi3HHHHUZKSophGLnflySX16FDh4r9jMX+XeYp7fHb7RviAQAuEdnp0owYz+x70lHJN+iimvj222919913a968eerRo4cOHjzoPEXyzDPPyOFwaODAgYqMjNTmzZtls9mKnO6IiopSUlKS1q9fr549exa7nyVLlqhJkyb6y1/+Uuxyi8VywVqbNm2qvn376tNPP9X06dO1fft27dmzR0uWLJHVWvzJkcLtPvnkk3r55ZfVtm1b+fv7KyMjQ1dddZWeeOIJhYSE6PPPP9fw4cPVsGFDdezYUZI0YcIErVu3TitWrFBERIQmTZqkbdu2qU2bNiXWOnjwYAUEBOiLL75QaGio3n77bfXq1Uv79u1TWFiYJOngwYNavny5Vq5cqVOnTun222/XCy+8oOeff16vvvqq9u3bpxYtWujZZ5+VlNvrU1F4RAEAoMpbuXKlqlWr5nwNHjxY06ZN05NPPqkRI0aoQYMGuv766/Xcc8/p7bffliR9/fXX+umnn/Tuu++qdevW6tmzp2bMmOHS7uDBgzV06FBdffXVio6O1oABA/T6668rJSXFuc6+ffvUpEkTl+3GjRvnrKVOnTql+gxNmzbVL7/84mxTkku7x48fd/mMb775ZpF9Dhw4UHFxcYqOjlbt2rX12GOPqU2bNmrQoIHGjh2rG2+8UR9++KEkKS0tTQkJCZo9e7Z69eqlli1batGiRecde7NhwwZt2bJFH330kdq3b6/GjRtr9uzZql69uj7++GPneg6HQwsXLlSLFi3Uo0cPDR8+3HkhUGhoqHx9fRUYGKioqChFRUXJy8urVL+jsqBHBgAuVz6BuT0jntq3G6699lrFx8c7p4OCgtSqVStt3LjR5SnTdrtdGRkZSk9P1549e1S3bl3FxJzrderSpYtLu15eXlqwYIGmT5+ub775Rps3b9aMGTP04osvasuWLYqOji62nsmTJ+vBBx/Up59+WiQclcQwjPP23tSsWVPbt2+XlDtYtvAjgNq3b+8ybbfbNWPGDH344Yf6/ffflZWVpczMTOd4l4MHDyorK0udOnVybhMWFlYklBW0Y8cOpaWlqWbNmi7zz549q4MHDzqnY2NjFRwc7JyOjo7W8ePHS2y3IrkdZBo0aKDExMQiH/L06dNq166dfv7553IrDgBQgSyWiz69U1mCgoLUqFEjl3lpaWmaNm2aBg4cWGR9d5/wXbt2bQ0fPlzDhw/Xc889pyuuuEJvvfWWpk2bpsaNG2vv3r0u69eqVUu1atVSREREqfexZ88e5wDlxo0bS5L27t2rtm3bSsoNVfmf0du76OE5KMj1u3rppZf06quvau7cuWrZsqWCgoI0bty4IgHIHWlpaYqOjtbatWuLLKtevbrzvY+Pj8syi8Uih8NR5v1eDLdPLf3yyy/OkdwFZWZm6vfffy+XogAAuJB27dpp7969atSoUZGX1WpVs2bNdOTIEedNXCWV6lE6NWrUUHR0tM6cOSNJGjp0qPbu3asVK1aUudaffvpJq1at0qBBgyRJbdu2VdOmTTV79uwyB4CNGzfq1ltv1V133aXWrVurQYMGzlNWUu5Na318fLR582bnvFOnTrmsU1i7du2UnJwsb2/vIr/T8PDwUtdW8KqvilbqHpl//etfzvdffvmlQkNDndN2u11r1qxRbGxsuRYHAEBJpkyZoltuuUX16tXTbbfdJqvVqh07dmjnzp2aPn26evfurSuuuEIjRozQSy+9pJSUFE2ePNmljbffflvbt2/XgAED1LBhQ2VkZOjdd9/Vrl279Nprr0mShgwZok8//VRDhgzRxIkT1adPH0VGRurXX3/VBx98UGT8R05OjpKTk+VwOHTy5EmtXbtW06dPV5s2bTRhwgRJuT0YCxYs0PXXX69u3bpp4sSJatasmbKzs7V+/Xr98ccfFxxX0rhxY3388cf67rvvVKNGDb3yyis6duyYmjdvLin3MUKjRo3ShAkTVLNmTUVERGjy5MklDi6WpN69e6tLly7q37+/Zs2apSuuuEJHjx7V559/rgEDBhQ5vVWS2NhYbd68Wb/88ouqVaumsLCw8+73YpQ6yPTv319S7i9/xIgRLst8fHwUGxurl19+uVyLAwCgJH369NHKlSv17LPP6sUXX5SPj4+aNm2q++67T5JktVq1bNkyjRo1Sh07dlRsbKzmzZunG2+80dlGx44dtWHDBv3tb3/T0aNHnTe6W758ua6++mpJuce9Dz74QPPnz9eCBQs0a9YsZWdnq06dOurVq5deeeUVl7p27dql6OhoeXl5KTQ0VM2bN9fEiRP1wAMPuDzKp3Pnztq6datmzJihMWPGKDk5WUFBQWrdurXmzJlzwbvlP/XUU/r555/Vp08fBQYGavTo0erfv7/zGYhS7umntLQ09evXT8HBwXr00UddlhdmsVj073//W5MnT9bIkSP1xx9/KCoqSj179lRkZGSpv5vHHntMI0aMUPPmzXX27FkdOnSowjo7LIZhGO5sEBcXp8TERLe6mDwpJSVFoaGhstlsCgkJ8XQ5AOARGRkZOnTokOLi4twePwJUlPP9XZb2+O32YN9Dhw4VmXf69GmXQUAAAACVwe0TVi+++KI++OAD5/TgwYMVFham2rVra8eOHeVaHAAAwPm4HWTeeust1a1bV5K0evVqff3111q1apX69u3rHMQEAABQGdw+tZScnOwMMitXrtTtt9+uG264QbGxsS433QEAAKhobvfI1KhRQ0eOHJEkrVq1Sr1795aUe8fCyrpmHABQNp66aRlQnPL4e3S7R2bgwIG688471bhxY508eVJ9+/aVJP3www9F7roIAKgafH19ZbVadfToUdWqVUu+vr6letghUBEMw1BWVpb++OMPWa1W+fr6lrktt4PMnDlzFBsbqyNHjmjWrFmqVq2aJCkpKUn/93//V+ZCAAAVx2q1Ki4uTklJSTp61EPPVwIKCQwMVL169S7qZnlu30fGbLiPDACcYxiGcnJyGAoAj/Py8pK3t3eJPYMVdh8ZSfrnP/+pt99+Wz///LM2bdqk+vXra+7cuYqLi9Ott95aliYBAJXAYrHIx8enyEP/ALNyuy8nPj5e48ePV9++fXX69Glnqq9evbrmzp1b3vUBAACUyO0g89prr2n+/PmaPHmyywOt2rdvrx9//LFciwMAADgft4PMoUOH1LZt2yLz/fz8nI88BwAAqAxuB5m4uDht3769yPxVq1apWbNm5VETAABAqZR6sO+zzz6rxx57TOPHj9eYMWOUkZEhwzC0ZcsWLVmyRDNnztQ//vGPiqwVAADARal7ZKZNm6a0tDTdd999evHFF/XUU08pPT1dd955p+Lj4/Xqq69qyJAhZS7khRdekMVi0bhx45zzMjIyNGbMGNWsWVPVqlXToEGDdOzYsTLvAwAAXFpKHWQK3m5m2LBh2r9/v9LS0pScnKzffvtNo0aNKnMRiYmJevvtt9WqVSuX+Y888og+++wzffTRR1q3bp2OHj2qgQMHlnk/AADg0uLWGJnCN60JDAxURETERRWQlpamYcOGaf78+apRo4Zzvs1mU0JCgl555RVdd911uuqqq7RgwQJ99913+v777y9qnwAA4NLgVpC54oorFBYWdt6Xu8aMGaObb77Z+fDJfFu3blV2drbL/KZNm6pevXratGlTie1lZmYqJSXF5QUAAC5Nbt3Zd9q0aQoNDS23nS9dulTbtm1TYmJikWXJycny9fVV9erVXeZHRkYqOTm5xDZnzpypadOmlVuNAACg6nIryAwZMuSiTyXlO3LkiB5++GGtXr1a/v7+5dKmJE2cOFHjx493TqekpKhu3brl1j4AAKg6Sn1qqbwf975161YdP35c7dq1k7e3t7y9vbVu3TrNmzdP3t7eioyMVFZWlk6fPu2y3bFjxxQVFVViu35+fgoJCXF5AQCAS1Ope2TK+yHZvXr1KvJIg5EjR6pp06Z64oknVLduXfn4+GjNmjUaNGiQJGnv3r06fPiwunTpUq61AAAAcyp1kHE4HOW64+DgYLVo0cJlXlBQkGrWrOmcP2rUKI0fP15hYWEKCQnR2LFj1aVLF3Xu3LlcawEAAObk1hiZyjZnzhxZrVYNGjRImZmZ6tOnj958801PlwUAAKoIi1He54yqmJSUFIWGhspmszFeBgAAkyjt8dvth0YCAABUFQQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWh4NMjNnzlSHDh0UHBysiIgI9e/fX3v37nVZJyMjQ2PGjFHNmjVVrVo1DRo0SMeOHfNQxQAAoCrxaJBZt26dxowZo++//16rV69Wdna2brjhBp05c8a5ziOPPKLPPvtMH330kdatW6ejR49q4MCBHqwaAABUFRbDMAxPF5Hvjz/+UEREhNatW6eePXvKZrOpVq1aWrx4sW677TZJ0k8//aRmzZpp06ZN6ty58wXbTElJUWhoqGw2m0JCQir6IwAAgHJQ2uN3lRojY7PZJElhYWGSpK1btyo7O1u9e/d2rtO0aVPVq1dPmzZtKraNzMxMpaSkuLwAAMClqcoEGYfDoXHjxqlbt25q0aKFJCk5OVm+vr6qXr26y7qRkZFKTk4utp2ZM2cqNDTU+apbt25Flw4AADykygSZMWPGaOfOnVq6dOlFtTNx4kTZbDbn68iRI+VUIQAAqGq8PV2AJD344INauXKl1q9frzp16jjnR0VFKSsrS6dPn3bplTl27JiioqKKbcvPz09+fn4VXTIAAKgCPNojYxiGHnzwQS1btkzffPON4uLiXJZfddVV8vHx0Zo1a5zz9u7dq8OHD6tLly6VXS4AAKhiPNojM2bMGC1evFgrVqxQcHCwc9xLaGioAgICFBoaqlGjRmn8+PEKCwtTSEiIxo4dqy5dupTqiiUAAHBp8+jl1xaLpdj5CxYs0D333CMp94Z4jz76qJYsWaLMzEz16dNHb775Zomnlgrj8msAAMyntMfvKnUfmYpAkAEAwHxMeR8ZAAAAdxBkAACAaRFkAACAaRFkAACAaRFkAACAaRFkAACAaRFkAACAaVWJZy0BAIAqzjCkM39IJ/ZLJ/ZJJw/kvj+5X7rxRemKGzxSFkEGAACck50h/flzbkA5sT8vsOyTThyQMm3Fb/PHTwQZAABQSQxDSjtWfO/K6cOS4ShhQ4tUva4UfoVUs7EU3ij3Z2SLSi2/IIIMAACXquyz0smDeb0rB/J+7sudl5lS8nZ+IVLNRlJ447zAkvcKayD5BFRe/aVAkAEAwMwMQ0pNKqF35YikEh6paLFK1esV7V0Jv0KqFiGV8GDnqoYgAwCAGWSl54aU/N6VE/ty3588KGWllbydf+i5XpWajXKDSn7virdf5dVfQQgyAABUFQ6HlHo0r3dlv+uAW9uRkrezeEk16uf1rhQ8JXSFFBRumt6VsiDIAABQ2TLT8npXDhQ4JZTXu5KdXvJ2ATVcx6zkv68RJ3n7Vl79VQhBBgCAiuBwSCm/Fd+7kvJ7ydtZvXODifNUUMHelZqVV79JEGQAALgYmakF7rdSYMDtyYNSztmStwuseW6QrXPAbWOpRqzk5VNp5ZsdQQYAgAtx2HPHqBQcZJsfXlKTSt7O6pM7qLZg70r+OJbAsMqr/xJGkAEAIF+GrcD9Vgr1rtgzS94uqFbxvSvV60teHGorEr9dAMDlxWGXTv9aqHclL7ykHSt5Oy9fKaxhgfutND4XXgJqVF79cEGQAQBcms6eKr535c+fJXtWydtViyzmyqBGub0rVq/Kqx+lQpABAJiXPSevd2V/0d6VM3+UvJ2XX96YlUaFQkuj3BvIwTQIMgCAqi/9T9dLmPPf/3lIcmSXvF1wtOvdbPN7V0Lr0rtyiSDIAACqBnu2dOqX4ntX0k+WvJ13QMm9K37BlVY+PIMgAwCoODlZuVcCZZzO/Xn2dN7707nvz54693TmU79IjpyS2wqpXah3Je9y5pA6ktVaGZ8GVRBBBgBQMsOQss6cCyNnT7v3/ny32y+OT2Chu9kW6F3xDSrXj4ZLA0EGAC51DnsJvSKlfH++XpLS8guR/KtLAaG5P/3zfgZUz72TbX54CY6hdwVuIcgAgBlkZ5SyJ+R0gSCSNz8z5eL3b/U+F0ACqhd6XyCUFPfeP5SBtagwBBkAqAyGkftMnrL2iuRkXHwNPoHnCSMXeO8bJFksF18DUM4IMgBQWvZsKSOlUO/H6dKNFcmwSYbjIguwSP4h5+/9cIaP6kV7Rbx9L3L/QNVDkAFw+TAMKfts2XtFstIuvgYv3zL0iuSFEb8Qxo8AhRBkAFQ+h0My7LmDUF1+FppvOPLeO4pZN29+1hn3ekXOd2v60vKtVopekdDig4lPAKdogHJEkAGKYxjnP3ied37hg3Q5HrSLbaO49sujxmLaMByl/zzn25+nWbzygoY7A1cLrMfTjIEqg/8ayyr9z9yBe8o74OUf+JyvwtN581Tc/MLr572/4LqFlhe7vlFCLYXXL+l9wXVLar+Y6YuuvZzqvuDvvIQDsAwP/WEhlyX3KheLV4Gf1kLTeT99AtwfuOoXTK8IcIkgyJTVmmnS1oWergKeVNxB1eLGAdhlfqH3pW2j2P1doI0iy4pbt4T1Sv15ylpj/n4IGQBKhyBTVl6+krd/3j+61nP/+FqskiyF5hdcXmhZsesWs16R9QsvL6GdEtsv5r07dRe7fkm1FVy/NHXnDWYssZZyrr2kg6rFev6DNgDA4yyGYVzSfegpKSkKDQ2VzWZTSEiIp8sBAAClUNrjN/9bCQAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATIsgAwAATMvb0wVUNMMwJOU+DhwAAJhD/nE7/zhekks+yKSmpkqS6tat6+FKAACAu1JTUxUaGlricotxoahjcg6HQ0ePHlVwcLAsFku5tZuSkqK6devqyJEjCgkJKbd2UXn4Ds2P79D8+A7NrSK/P8MwlJqaqpiYGFmtJY+EueR7ZKxWq+rUqVNh7YeEhPAfn8nxHZof36H58R2aW0V9f+fricnHYF8AAGBaBBkAAGBaBJky8vPz0zPPPCM/Pz9Pl4Iy4js0P75D8+M7NLeq8P1d8oN9AQDApYseGQAAYFoEGQAAYFoEGQAAYFoEGQAAYFoEmTJYv369+vXrp5iYGFksFi1fvtzTJcENM2fOVIcOHRQcHKyIiAj1799fe/fu9XRZcEN8fLxatWrlvAlXly5d9MUXX3i6LJTRCy+8IIvFonHjxnm6FJTS1KlTZbFYXF5Nmzb1SC0EmTI4c+aMWrdurTfeeMPTpaAM1q1bpzFjxuj777/X6tWrlZ2drRtuuEFnzpzxdGkopTp16uiFF17Q1q1b9d///lfXXXedbr31Vu3atcvTpcFNiYmJevvtt9WqVStPlwI3XXnllUpKSnK+NmzY4JE6LvlHFFSEvn37qm/fvp4uA2W0atUql+mFCxcqIiJCW7duVc+ePT1UFdzRr18/l+nnn39e8fHx+v7773XllVd6qCq4Ky0tTcOGDdP8+fM1ffp0T5cDN3l7eysqKsrTZdAjA9hsNklSWFiYhytBWdjtdi1dulRnzpxRly5dPF0O3DBmzBjdfPPN6t27t6dLQRns379fMTExatCggYYNG6bDhw97pA56ZHBZczgcGjdunLp166YWLVp4uhy44ccff1SXLl2UkZGhatWqadmyZWrevLmny0IpLV26VNu2bVNiYqKnS0EZdOrUSQsXLlSTJk2UlJSkadOmqUePHtq5c6eCg4MrtRaCDC5rY8aM0c6dOz12bhdl16RJE23fvl02m00ff/yxRowYoXXr1hFmTODIkSN6+OGHtXr1avn7+3u6HJRBweEVrVq1UqdOnVS/fn19+OGHGjVqVKXWQpDBZevBBx/UypUrtX79etWpU8fT5cBNvr6+atSokSTpqquuUmJiol599VW9/fbbHq4MF7J161YdP35c7dq1c86z2+1av369Xn/9dWVmZsrLy8uDFcJd1atX1xVXXKEDBw5U+r4JMrjsGIahsWPHatmyZVq7dq3i4uI8XRLKgcPhUGZmpqfLQCn06tVLP/74o8u8kSNHqmnTpnriiScIMSaUlpamgwcPavjw4ZW+b4JMGaSlpbmkzkOHDmn79u0KCwtTvXr1PFgZSmPMmDFavHixVqxYoeDgYCUnJ0uSQkNDFRAQ4OHqUBoTJ05U3759Va9ePaWmpmrx4sVau3atvvzyS0+XhlIIDg4uMiYtKChINWvWZKyaSTz22GPq16+f6tevr6NHj+qZZ56Rl5eXhg4dWum1EGTK4L///a+uvfZa5/T48eMlSSNGjNDChQs9VBVKKz4+XpJ0zTXXuMxfsGCB7rnnnsovCG47fvy47r77biUlJSk0NFStWrXSl19+qeuvv97TpQGXhd9++01Dhw7VyZMnVatWLXXv3l3ff/+9atWqVem1WAzDMCp9rwAAAOWA+8gAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAgHLv9Dxu3DhPlwHATQQZAJXmnnvukcVikcVikY+Pj+Li4vT4448rIyPD06UBMCmetQSgUt14441asGCBsrOztXXrVo0YMUIWi0Uvvviip0sDYEL0yACoVH5+foqKilLdunXVv39/9e7dW6tXr5YkZWZm6qGHHlJERIT8/f3VvXt3JSYmOrdduHChqlev7tLe8uXLZbFYnNNTp05VmzZt9M9//lOxsbEKDQ3VkCFDlJqa6lznzJkzuvvuu1WtWjVFR0fr5ZdfrtgPDaDCEGQAeMzOnTv13XffydfXV5L0+OOP65NPPtGiRYu0bds2NWrUSH369NGff/7pVrsHDx7U8uXLtXLlSq1cuVLr1q3TCy+84Fw+YcIErVu3TitWrNBXX32ltWvXatu2beX62QBUDoIMgEq1cuVKVatWTf7+/mrZsqWOHz+uCRMm6MyZM4qPj9dLL72kvn37qnnz5po/f74CAgKUkJDg1j4cDocWLlyoFi1aqEePHho+fLjWrFkjSUpLS1NCQoJmz56tXr16qWXLllq0aJFycnIq4uMCqGCMkQFQqa699lrFx8frzJkzmjNnjry9vTVo0CD973//U3Z2trp16+Zc18fHRx07dtSePXvc2kdsbKyCg4Od09HR0Tp+/Lik3N6arKwsderUybk8LCxMTZo0uchPBsATCDIAKlVQUJAaNWokSXrnnXfUunVrJSQkqEOHDhfc1mq1yjAMl3nZ2dlF1vPx8XGZtlgscjgcF1E1gKqKU0sAPMZqtWrSpEl66qmn1LBhQ/n6+mrjxo3O5dnZ2UpMTFTz5s0lSbVq1VJqaqrOnDnjXGf79u1u7bNhw4by8fHR5s2bnfNOnTqlffv2XdyHAeARBBkAHjV48GB5eXkpPj5eDzzwgCZMmKBVq1Zp9+7duv/++5Wenq5Ro0ZJkjp16qTAwEBNmjRJBw8e1OLFi7Vw4UK39letWjWNGjVKEyZM0DfffKOdO3fqnnvukdXKP4eAGXFqCYBHeXt768EHH9SsWbN06NAhORwODR8+XKmpqWrfvr2+/PJL1ahRQ1LuWJb33ntPEyZM0Pz589WrVy9NnTpVo0ePdmufL730ktLS0tSvXz8FBwfr0Ucflc1mq4iPB6CCWYzCJ5wBAABMgr5UAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWv8Px5FBBW7YmNwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([fedavg_df, fedsgd_gradient_df], ignore_index=True)\n",
    "ax = sns.lineplot(df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=0)\n",
    "_ = ax.set_xticks(df[\"Round\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
