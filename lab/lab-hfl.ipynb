{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the lab on Horizontal Federated Learning, comprised of Tutorials 1A, 1B, and Homework 1, presents the findings and uses part of the experimental methodology from the [original Federated Learning](https://arxiv.org/pdf/1602.05629.pdf) paper. In horizontal federated learning, all clients have access to the same complete model architecture, which they train on local data, sharing information about model updates but not their data.\n",
    "\n",
    "Before starting, make sure to follow the overall setup for the lab.\n",
    "\n",
    "This first tutorial sets up some of the prerequisite code for later on and reproduces a basic centralized training setup where the server has all the data and involves no other clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, we download, load, and preprocess the [MNIST dataset](https://archive.ics.uci.edu/dataset/683/mnist+database+of+handwritten+digits), which we will use for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:38.913449Z",
     "iopub.status.busy": "2024-03-09T18:44:38.912785Z",
     "iopub.status.idle": "2024-03-09T18:44:42.072289Z",
     "shell.execute_reply": "2024-03-09T18:44:42.070117Z",
     "shell.execute_reply.started": "2024-03-09T18:44:38.913387Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_path_str = \"./data\"\n",
    "ETA = \"\\N{GREEK SMALL LETTER ETA}\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # normalize by training set mean and standard deviation\n",
    "    # resulting data has mean=0 and std=1\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_path_str, train=True, download=True, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path_str, train=False, download=False, transform=transform),\n",
    "    # decrease batch size if running into memory issues when testing\n",
    "    # a bespoke generator is passed to avoid reproducibility issues\n",
    "    shuffle=False, drop_last=False, batch_size=10000, generator=torch.Generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a small convolutional neural network that will serve as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.075662Z",
     "iopub.status.busy": "2024-03-09T18:44:42.074978Z",
     "iopub.status.idle": "2024-03-09T18:44:42.090236Z",
     "shell.execute_reply": "2024-03-09T18:44:42.089004Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.075616Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MnistCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can define a helper method, which, given a model, a loader for iterating through a set of data, and an optimizer for updating the model trains one epoch (i.e., learns going through all the available data once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.091810Z",
     "iopub.status.busy": "2024-03-09T18:44:42.091492Z",
     "iopub.status.idle": "2024-03-09T18:44:42.231435Z",
     "shell.execute_reply": "2024-03-09T18:44:42.229081Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.091782Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, loader: DataLoader, optimizer: Optimizer) -> None:\n",
    "    model.train()\n",
    "\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define another utility method that splits the whole dataset into the requested number of chunks, picking samples within chunks in a (non-)IID (independent and identically distributed) fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.237506Z",
     "iopub.status.busy": "2024-03-09T18:44:42.236729Z",
     "iopub.status.idle": "2024-03-09T18:44:42.296334Z",
     "shell.execute_reply": "2024-03-09T18:44:42.293947Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.237445Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def split(nr_clients: int, iid: bool, seed: int) -> list[Subset]:\n",
    "    rng = npr.default_rng(seed)\n",
    "\n",
    "    if iid:\n",
    "        splits = np.array_split(rng.permutation(len(train_dataset)), nr_clients)\n",
    "    else:\n",
    "        sorted_indices = np.argsort(np.array([target for _data, target in train_dataset]))\n",
    "        shards = np.array_split(sorted_indices, 2 * nr_clients)\n",
    "        shuffled_shard_indices = rng.permutation(len(shards))\n",
    "        splits = [\n",
    "            np.concatenate([shards[i] for i in inds], dtype=np.int64)\n",
    "            for inds in shuffled_shard_indices.reshape(-1, 2)]\n",
    "\n",
    "    return [Subset(train_dataset, split) for split in cast(list[list[int]], splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.299749Z",
     "iopub.status.busy": "2024-03-09T18:44:42.298934Z",
     "iopub.status.idle": "2024-03-09T18:44:42.381538Z",
     "shell.execute_reply": "2024-03-09T18:44:42.379111Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.299680Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_split = split(100, True, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a short class for holding the results of training runs and the parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.384682Z",
     "iopub.status.busy": "2024-03-09T18:44:42.383975Z",
     "iopub.status.idle": "2024-03-09T18:44:42.868293Z",
     "shell.execute_reply": "2024-03-09T18:44:42.867327Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.384616Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass, field\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    algorithm: str\n",
    "    n: int  # number of clients\n",
    "    c: float  # client_fraction\n",
    "    b: int  # take -1 as inf\n",
    "    e: int  # nr_local_epochs\n",
    "    lr: float  # printed as lowercase eta\n",
    "    seed: int\n",
    "    wall_time: list[float] = field(default_factory=list)\n",
    "    message_count: list[int] = field(default_factory=list)\n",
    "    test_accuracy: list[float] = field(default_factory=list)\n",
    "\n",
    "    def as_df(self, skip_wtime=True) -> DataFrame:\n",
    "        self_dict = {\n",
    "            k.capitalize().replace(\"_\", \" \"): v\n",
    "            for k, v in asdict(self).items()}\n",
    "\n",
    "        if self_dict[\"B\"] == -1:\n",
    "            self_dict[\"B\"] = \"\\N{INFINITY}\"\n",
    "\n",
    "        df = DataFrame({\"Round\": range(1, len(self.wall_time) + 1), **self_dict})\n",
    "        df = df.rename(columns={\"Lr\": ETA})\n",
    "        if skip_wtime:\n",
    "            df = df.drop(columns=[\"Wall time\"])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an abstract class as a template for all distributed learning clients, defining a method for outputting an update after training a given model on local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.869553Z",
     "iopub.status.busy": "2024-03-09T18:44:42.869184Z",
     "iopub.status.idle": "2024-03-09T18:44:42.876664Z",
     "shell.execute_reply": "2024-03-09T18:44:42.875660Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.869528Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Client(ABC):\n",
    "    def __init__(self, client_data: Subset, batch_size: int) -> None:\n",
    "        self.model = MnistCnn().to(device)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            client_data, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the flip side, a server needs to be able to run the (distributed) training process for a given number of rounds and test the current model it possesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.877775Z",
     "iopub.status.busy": "2024-03-09T18:44:42.877546Z",
     "iopub.status.idle": "2024-03-09T18:44:42.955572Z",
     "shell.execute_reply": "2024-03-09T18:44:42.953174Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.877753Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server(ABC):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        self.clients: list[Client]\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = MnistCnn().to(device)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        ...\n",
    "\n",
    "\n",
    "    def test(self) -> float:\n",
    "        correct = 0\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = self.model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        return 100. * correct / len(cast(datasets.MNIST, test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the previously defined server template, we can even formulate a centralized variant, which does not involve clients, as a precursor to distributed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:42.959246Z",
     "iopub.status.busy": "2024-03-09T18:44:42.958485Z",
     "iopub.status.idle": "2024-03-09T18:44:43.013245Z",
     "shell.execute_reply": "2024-03-09T18:44:43.010930Z",
     "shell.execute_reply.started": "2024-03-09T18:44:42.959193Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "        self.clients = []\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(\"Centralized\", 1, 1, self.batch_size, 1, self.lr, self.seed)\n",
    "\n",
    "        for epoch in tqdm(range(nr_rounds), desc=\"Epochs\", leave=False):\n",
    "            start_time = perf_counter()\n",
    "            self.generator.manual_seed(self.seed + epoch + 1)\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "            elapsed_time += perf_counter() - start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(0)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:43.021047Z",
     "iopub.status.busy": "2024-03-09T18:44:43.020451Z",
     "iopub.status.idle": "2024-03-09T18:44:43.067919Z",
     "shell.execute_reply": "2024-03-09T18:44:43.065689Z",
     "shell.execute_reply.started": "2024-03-09T18:44:43.020998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncentralized_server = CentralizedServer(0.5, 1024, 42)\\nresult_centralized = centralized_server.run(5)\\ncentralized_df = result_centralized.as_df()\\ncentralized_df\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "centralized_server = CentralizedServer(0.5, 1024, 42)\n",
    "result_centralized = centralized_server.run(5)\n",
    "centralized_df = result_centralized.as_df()\n",
    "centralized_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the template with some setup steps common to all decentralized algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:43.070759Z",
     "iopub.status.busy": "2024-03-09T18:44:43.070251Z",
     "iopub.status.idle": "2024-03-09T18:44:43.251723Z",
     "shell.execute_reply": "2024-03-09T18:44:43.249160Z",
     "shell.execute_reply.started": "2024-03-09T18:44:43.070720Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.nr_clients = len(client_subsets)\n",
    "        self.client_fraction = client_fraction\n",
    "        self.client_sample_counts = [len(subset) for subset in client_subsets]\n",
    "        self.nr_clients_per_round = max(1, round(client_fraction * self.nr_clients))\n",
    "        self.rng = npr.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second tutorial implements the two federated learning algorithms from the same paper referenced previously and gives a quick overview of plotting metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the FedSGD algorithm, the baseline from the paper, we first need to define the client, and we choose to pass gradients from the client as the update result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:43.255937Z",
     "iopub.status.busy": "2024-03-09T18:44:43.254863Z",
     "iopub.status.idle": "2024-03-09T18:44:43.299274Z",
     "shell.execute_reply": "2024-03-09T18:44:43.296826Z",
     "shell.execute_reply.started": "2024-03-09T18:44:43.255845Z"
    }
   },
   "outputs": [],
   "source": [
    "class GradientClient(Client):\n",
    "    def __init__(self, client_data: Subset) -> None:\n",
    "        super().__init__(client_data, len(client_data))\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # do the local training and send back the gradients\n",
    "\n",
    "        # copy the data from the server\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "                client_values.grad = None\n",
    "\n",
    "        # seeding is not strictly necessary here\n",
    "        self.generator.manual_seed(seed)\n",
    "        self.model.train()\n",
    "\n",
    "        # this will always have one iteration on the batch with all entries\n",
    "        for data, target in self.loader_train:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "        # send back the gradient to the server\n",
    "        return [\n",
    "            cast(torch.Tensor, x.grad).detach().cpu().clone()\n",
    "            for x in self.model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the corresponding server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:43.303070Z",
     "iopub.status.busy": "2024-03-09T18:44:43.302312Z",
     "iopub.status.idle": "2024-03-09T18:44:43.348137Z",
     "shell.execute_reply": "2024-03-09T18:44:43.345884Z",
     "shell.execute_reply.started": "2024-03-09T18:44:43.302949Z"
    }
   },
   "outputs": [],
   "source": [
    "# decentralized cause everyone has its own data\n",
    "\n",
    "class FedSgdGradientServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float,\n",
    "            client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, -1, client_subsets, client_fraction, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.clients = [GradientClient(subset) for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0. # starting a timer\n",
    "        run_result = RunResult(\"FedSGDGradient\", self.nr_clients, self.client_fraction, -1, 1, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train() # training mode\n",
    "            self.optimizer.zero_grad() # ensure clean gradients\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()] # will be sent to the clients\n",
    "            indices_chosen_clients = self.rng.choice(self.nr_clients, self.nr_clients_per_round, replace=False) # nb of clients that will be communicate with fot a round\n",
    "            chosen_sum_nr_samples = sum(self.client_sample_counts[i] for i in indices_chosen_clients)\n",
    "            chosen_adjusted_gradients: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            # getting the updates from the clients\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_gradients = self.clients[ind].update(weights, client_round_seed) # compute your updates\n",
    "                chosen_adjusted_gradients.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_gradients]) # weighted averaging comparing how many sample the client has compared to the total\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_gradients: list[torch.Tensor] = [sum(x) for x in zip(*chosen_adjusted_gradients)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for client_gradient, server_parameter in zip(averaged_chosen_gradients, self.model.parameters()):\n",
    "                    server_parameter.grad = client_gradient.to(device=device) # from the clients update to the server meaning after that our model has been updated\n",
    "\n",
    "            self.optimizer.step()\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:44:43.350955Z",
     "iopub.status.busy": "2024-03-09T18:44:43.350328Z",
     "iopub.status.idle": "2024-03-09T18:49:47.738939Z",
     "shell.execute_reply": "2024-03-09T18:49:46.374621Z",
     "shell.execute_reply.started": "2024-03-09T18:44:43.350897Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>N</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "      <th>η</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Wall time</th>\n",
       "      <th>Message count</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedSGDGradient</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>6.9</td>\n",
       "      <td>40</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round       Algorithm    N    C  B  E     η  Seed  Wall time  \\\n",
       "0      1  FedSGDGradient  100  0.2  ∞  1  0.02    42        6.9   \n",
       "\n",
       "   Message count  Test accuracy  \n",
       "0             40           8.89  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedsgd_gradient_server = FedSgdGradientServer(0.02, sample_split, 0.2, 42)\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(1)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df(skip_wtime=False)\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FedAvg algorithm is the paper's main contribution, requiring a client that passes around weights instead of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:49:49.969282Z",
     "iopub.status.busy": "2024-03-09T18:49:49.920398Z",
     "iopub.status.idle": "2024-03-09T18:49:52.476162Z",
     "shell.execute_reply": "2024-03-09T18:49:52.472011Z",
     "shell.execute_reply.started": "2024-03-09T18:49:49.969075Z"
    }
   },
   "outputs": [],
   "source": [
    "class WeightClient(Client):\n",
    "    def __init__(self, client_data: Subset, lr: float, batch_size: int, nr_epochs: int) -> None:\n",
    "        super().__init__(client_data, batch_size)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.nr_epochs = nr_epochs\n",
    "\n",
    "    # get the weights from the server\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "\n",
    "        self.generator.manual_seed(seed) # for reproducibility reasons\n",
    "\n",
    "        for _epoch in range(self.nr_epochs):\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "\n",
    "        return [x.detach().cpu().clone() for x in self.model.parameters()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we define the actual server code for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:49:52.591295Z",
     "iopub.status.busy": "2024-03-09T18:49:52.590429Z",
     "iopub.status.idle": "2024-03-09T18:49:53.828397Z",
     "shell.execute_reply": "2024-03-09T18:49:53.825903Z",
     "shell.execute_reply.started": "2024-03-09T18:49:52.591227Z"
    }
   },
   "outputs": [],
   "source": [
    "class FedAvgServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, nr_local_epochs: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedAvg\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        elapsed_time = 0.\n",
    "        run_result = RunResult(self.name, self.nr_clients, self.client_fraction, self.batch_size, self.nr_local_epochs, self.lr, self.seed)\n",
    "\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(self.nr_clients, self.nr_clients_per_round, replace=False)\n",
    "            chosen_sum_nr_samples = sum(self.client_sample_counts[i] for i in indices_chosen_clients)\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append([\n",
    "                    self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                     for tens in client_weights])\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_chosen_weights: list[torch.Tensor] = [sum(x) for x in zip(*chosen_adjusted_weights)]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for client_weight, server_parameter in zip(averaged_chosen_weights, self.model.parameters()):\n",
    "                    server_parameter[:] = client_weight.to(device=device)\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(2 * (nr_round + 1) * self.nr_clients_per_round)\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:49:53.961068Z",
     "iopub.status.busy": "2024-03-09T18:49:53.960127Z",
     "iopub.status.idle": "2024-03-09T19:31:51.325905Z",
     "shell.execute_reply": "2024-03-09T19:31:50.586665Z",
     "shell.execute_reply.started": "2024-03-09T18:49:53.960959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fedavg_server = FedAvgServer(0.02, 200, sample_split, 0.2, 2, 42)\n",
    "result_fedavg = fedavg_server.run(5)\n",
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at a quick example of plotting the accuracy per round of the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-09T19:31:52.392734Z",
     "iopub.status.idle": "2024-03-09T19:31:52.413475Z",
     "shell.execute_reply": "2024-03-09T19:31:52.412880Z",
     "shell.execute_reply.started": "2024-03-09T19:31:52.412754Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([fedavg_df, fedsgd_gradient_df], ignore_index=True)\n",
    "ax = sns.lineplot(df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=0)\n",
    "_ = ax.set_xticks(df[\"Round\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
